{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "c271f564",
=======
   "execution_count": 6,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from the r/politics\n",
    "from psaw import PushshiftAPI\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "2175de05",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "# 1. Motivation\n",
    "\n",
    "### The Reddit dataset\n",
    "\n",
    "For this project, we chose to work with data from the [r/politics](https://www.reddit.com/r/politics/) subreddit, an online forum with 8 million members \"for current and explicitly political U.S. news.\" according to the rules stated on the site. \n",
    "\n",
    "Visitors at r/politics will quickly notice that the majority of the submissions are by users posting links to news articles published on news media sites like CNN or The Huffington Post. The headlines of these linked articles are then shown on r/politics as the titles of the submissions. Other users can then comment on the linked article, which is what ultimately constitutes the actual user-generated content on the site. \n",
    "\n",
    "We focused our data extraction to only include submissions from r/politics that fulfilled the following criteria: \n",
    "* __They contained \"Trump\" or \"Biden\" in the title.__ While submissions containing other words and names than \"Trump\" and \"Biden\" (e.g. \"Republican\" and \"Democrat\") might be used to provide equally good indications of the political convictions of redditors, this textual query allowed us to limit the scope of the project while still extracting data essential to the aim of this project. \n",
    "* __They had received more than five comments.__ This requirement was to prevent us from downloading submissions with no or only a very small comments section, as we'll be using the comments to conduct the later sentiment analysis and produce a partitioning of the redditors. \n",
    "* __They had been published between 10-1-2020 and 11-3-2020.__ This period covered approximately a month before the most recent U.S. presidential election that took place on 11-3-2020. Ideally, we would have covered several months leading up to the election day, in order to detect longer term trends in the data. However, that would prove to be computationally infeasible, given the amount of data this would yield. \n",
    "\n",
    "__Submission variables__\n",
    "\n",
    "The downloaded submissions would be structured in a Pandas dataframe containing the following variables for each submission in its respective columns: \n",
    "1. __time stamp index:__ Simply stating when the submissions was made.\n",
    "2. __title:__ Being the title of the submission. Usually the header of the linked article. \n",
    "3. __id:__ A unique identifier for a particular submission. \n",
    "4. __author:__ The profile name of the author of the submissions.\n",
    "5. __num_comments:__ The number of comments received on the particular submission.\n",
    "6. __url:__ The link stated in the text of the submission.\n",
    "\n",
    "Our query to extract comments from the r/politics subreddit was also focused to only include comments fulfilling the following criteria: \n",
    "* __They were related to one of the downloaded submissions.__ \n",
    "* __They were posted no later than 11-10-2020.__ By including comments posted up to one week after the election day, we would ensure that we would also have some comments for any submissions made on the election day, without including comments that were made way after the objective period, which would not be representative of the sentiment during the objective period. \n",
    "\n",
    "__Comments variables__\n",
    "\n",
    "As stated, we would download the associated comments section for all the downloaded submissions. Similarly to the submissions, the comments would be structured in a Pandas dataframe containing the following variables for each comment in its respective columns:\n",
    "1. __time stamp index:__ Simply stating when the submissions was made.\n",
    "2. __id:__ A unique identifier for a particular submission. \n",
    "3. __link_id:__ A unique identifier for the original submission to which the comment relates, somewhere in the comments section.\n",
    "4. __author:__ The profile name of the author of the submissions.\n",
    "5. __parent_id:__ A unique identifier for the post to which the comment was made. This may either be a submission or a comment, which is indicated with with the parent_id starting with either \"t3_\" or \"t1_\".\n",
    "6. __body:__ The textual content of the comment. \n",
    "\n",
    "\n",
    "__Reasons for choosing this particular data set__ <br>\n",
    "1. Easy to collect using the Pushshift API.\n",
    "2. Interesting topic that would fit the requirements of the project.\n",
    "3. Similar format as the data we've previously worked with.\n",
    "\n",
    "### The polling dataset\n",
    "NEEDS EXPLANATION\n",
    "\n",
    "\n",
    "### Goal for end user's experience\n",
    "Our goal is for the end user's of our website to have a blast digesting our the findings of our analyses presented in a beautiful and thought-provoking way. \n",
    "\n",
    "Below, we show how we got the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
<<<<<<< HEAD
   "id": "f2ab391f",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lasse\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n"
     ]
    }
   ],
   "source": [
    "# Note this is just a POC with a limit=100. \n",
    "api = PushshiftAPI()\n",
    "\n",
    "my_subreddit = \"politics\"\n",
    "query = \"Trump | Biden \"\n",
    "\n",
    "date1 = int(datetime.datetime(2020,10,1).timestamp())\n",
    "date2 = int(datetime.datetime(2020,11,3).timestamp())\n",
    "\n",
    "gen = api.search_submissions(num_comments= '>5',\n",
    "                             subreddit=my_subreddit, \n",
    "                             after=date1, \n",
    "                             before=date2, \n",
    "                             q=query\n",
    "                             #,limit=100\n",
    "                            )\n",
    "results = list(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
<<<<<<< HEAD
   "id": "f5705a3b",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['title', 'id', 'author', 'num_comments', 'url']\n",
    "\n",
    "subs_df = pd.DataFrame(\n",
    "    {\n",
    "        column_names[0] : [submission.d_[column_names[0]] for submission in results],\n",
    "        column_names[1] : [submission.d_[column_names[1]] for submission in results],\n",
    "        column_names[2] : [submission.d_[column_names[2]] for submission in results],\n",
    "        column_names[3] : [submission.d_[column_names[3]] for submission in results],\n",
    "        column_names[4] : [submission.d_[column_names[4]] for submission in results]\n",
    "    },\n",
    "    index = [submission.d_['created_utc'] for submission in results])\n",
    "subs_df.index = pd.to_datetime(subs_df.index, unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "a580d246",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "To ensure that each submissions is unambigously related to either one of the candidates, we simply remove all submissions containing both \"Trump\" and \"Biden\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
<<<<<<< HEAD
   "id": "9be5f9ff",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to contain indices of subs in df with a title containing both \"Trump\" and \"Biden\"\n",
    "TB = []\n",
    "for i in range(len(subs_df['title'])):\n",
    "    if (re.search('Trump', subs_df['title'][i])) and (re.search('Biden', subs_df['title'][i])):\n",
    "        TB.append(i)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "subs_df = subs_df.drop(subs_df.index[TB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
<<<<<<< HEAD
   "id": "fef0febb",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = subs_df"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "51a8ee7c",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "Now we're ready to download the associated comments sections for each of the remaining submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
<<<<<<< HEAD
   "id": "37c11988",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/82 [00:00<?, ?it/s]C:\\Users\\Lasse\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n",
      " 12%|█▏        | 10/82 [00:16<01:44,  1.46s/it]C:\\Users\\Lasse\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "C:\\Users\\Lasse\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n",
      "100%|██████████| 82/82 [04:32<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "date3 = int(datetime.datetime(2020,11,10).timestamp())\n",
    "\n",
    "comments = []\n",
    "for link_id in tqdm(subs_df['id']):\n",
    "    gen = api.search_comments(subreddit=my_subreddit,\n",
    "                              link_id=link_id,\n",
    "                              before=date3)\n",
    "    comment_sec = list(gen)\n",
    "    comments += comment_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
<<<<<<< HEAD
   "id": "fed9a93b",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['id', 'link_id', 'author', 'parent_id', 'body']\n",
    "\n",
    "coms_df = pd.DataFrame(\n",
    "    {\n",
    "        column_names[0] : [comment.d_[column_names[0]] for comment in comments],\n",
    "        column_names[1] : [comment.d_[column_names[1]] for comment in comments],\n",
    "        column_names[2] : [comment.d_[column_names[2]] for comment in comments],\n",
    "        column_names[3] : [comment.d_[column_names[3]] for comment in comments],\n",
    "        column_names[4] : [comment.d_[column_names[4]] for comment in comments]\n",
    "    },\n",
    "    columns= column_names, index = [comment.d_['created_utc'] for comment in comments])\n",
    "\n",
    "coms_df.index = pd.to_datetime(coms_df.index, unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "f31362fe",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "# 2 Cleaning, preprocessing and stats\n",
    "\n",
    "### Processing the submissions\n",
    "\n",
    "__Determining the mentioned politician__<br>\n",
    "We need to determine whether the collected submissions are relating to either Trump or Biden, as we have already removed all the submissions including both names. We do this simply by searching the title of the submissions for these names and adding a \"politician\" variable to each submission stating which of the politians are mentioned. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "dc884b95",
=======
   "execution_count": 4,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading all the submissions (processed)\n",
    "local_storage = r\"C:\\Users\\JaQtae\\Desktop\\SocInfo2022\\Data\\Archive\\politics_subs_big.csv\"\n",
    "sub_data = pd.read_csv(local_storage,index_col=0,parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 883,
   "id": "e9a34bc1",
=======
   "execution_count": 10,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JaQtae\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 9044/9044 [00:00<00:00, 394284.11it/s]\n"
     ]
    }
   ],
   "source": [
    "def determine_politician_subs(title):\n",
    "        if (re.search('Trump', title)):\n",
    "            return 'Trump'\n",
    "        else:\n",
    "            return 'Biden'\n",
    "tqdm.pandas()\n",
    "sub_data['politician'] = sub_data['title'].progress_apply(determine_politician_subs)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "c8f2f66b",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "In this section we will dicuss our cleaning and preprocessing of the collected data.\n",
    "Our main data is the collected comments dataframe. \n",
    "\n",
    "### Cleaning and preprocessing the comments\n",
    "The main reason for having to clean the comments data is to prepare it for the later sentiment analysis. For this analysis, we will be using the Valence Aware Dictionary and sEntiment Reasoner ([VADER](https://towardsdatascience.com/an-short-introduction-to-vader-3f3860208d53)) module from the nltk.sentiment library, which has been specifically created to work with text produced on social media. One of the great features of this module is that it is quite robust in terms of the needed data cleaning and processing to function properly. Typical processing steps like tokenization and stemming as well as removing stop words are consequently not required to have the VADER module work well and provide an indication of the sentiment of a body of text. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1041,
   "id": "4e052a57",
=======
   "execution_count": 11,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading all the comments data (not processed)\n",
    "#url = 'https://raw.githubusercontent.com/JaQtae/SocInfo2022/FinalProject/Data/politics_comments_very_smol_fully_processed.csv'\n",
    "local_storage = r\"C:\\Users\\JaQtae\\Desktop\\SocInfo2022\\Data\\politics_comments_big.csv\"\n",
    "com_data = pd.read_csv(local_storage,index_col=0,parse_dates=[0])\n",
    "# The collected comments data set still contained some data from 2020-09-30. This is removed. \n",
    "com_data = com_data[com_data.index > \"2020-10-01\"]\n",
    "\n",
    "# Make sure all text bodies are of type string. \n",
    "com_data[\"body\"] = com_data[\"body\"].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "f881852f",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "__Removing deleted comments__<br>\n",
    "Some of the comments have been removed after being posted, so we'll do some cleaning first by filtering out the comments where author = \"[deleted]\", which will do the job. Similarly, we found that a large part of the comments were made by moderator robots reminding real redditors to behave in accordance with the subreddit rules. Comments made by these bots are also removed. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1042,
   "id": "a5e27600",
=======
   "execution_count": 12,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "com_data = com_data.drop(com_data[com_data['author'] == '[deleted]'].index)\n",
    "com_data = com_data.drop(com_data[com_data['author'] == 'AutoModerator'].index)\n",
    "com_data = com_data.drop(com_data[com_data['author'] == 'PoliticsModeratorBot'].index)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "59aae918",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "__Removing comments by authors with less than 50 comments__<br>\n",
    "We also remove all comments by authors who have posted less than 50 comments in total. The reason for this being that we would like to have a more solid foundation on which to infer the political convictions of the redditors, which would not be achieved if we had only very few comments made by them."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1043,
   "id": "fc006f24",
=======
   "execution_count": 13,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "com_data = com_data.groupby('author').filter(lambda x : len(x)>=50)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "a84da6c4",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "__Finding parent authors for the comments__<br>\n",
    "To later build our network of redditors, we will populate the comments dataframe with the names of the parent authors.\n",
    "This will create some [deleted] and NaN values which we will delete."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1045,
   "id": "23137ae7",
=======
   "execution_count": 14,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_authors = dict(zip(com_data.id, com_data.author))\n",
    "parent = dict(zip(com_data.id, com_data.parent_id))\n",
    "submission_authors = dict(zip(sub_data.id, sub_data.author))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1047,
   "id": "3937bcfd",
=======
   "execution_count": 15,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299428/299428 [00:00<00:00, 496536.03it/s]\n",
      "C:\\Users\\Lasse\\AppData\\Local\\Temp/ipykernel_25688/4142414443.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  com_data[\"parent_author\"] = com_data.id.progress_apply(find_parent_author)\n"
     ]
    }
   ],
   "source": [
    "def find_parent_author(comment_id):\n",
    "    parent_id = parent[comment_id]    \n",
    "    \n",
    "    if parent_id[:3] == 't1_':\n",
    "        return comment_authors.get(parent_id[3:], None)\n",
    "    \n",
    "    elif parent_id[:3] == 't3_':\n",
    "        return submission_authors.get(parent_id[3:], None)\n",
    "\n",
    "com_data[\"parent_author\"] = com_data.id.progress_apply(find_parent_author)\n",
    "com_data = com_data.drop(com_data[com_data['parent_author'] == '[deleted]'].index) # Remove deleteds\n",
    "com_data = com_data.drop(com_data[com_data['parent_author'].isna()].index) # Remove NaN's"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 897,
   "id": "52215d84",
=======
   "execution_count": 17,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading all the comments data (processed)\n",
    "#url = 'https://raw.githubusercontent.com/JaQtae/SocInfo2022/FinalProject/Data/politics_comments_very_smol_fully_processed.csv'\n",
    "local_storage = local_storage = r\"C:\\Users\\JaQtae\\Desktop\\SocInfo2022\\Data\\politics_comments_big_processed.csv\"\n",
    "com_data = pd.read_csv(local_storage,index_col=0,parse_dates=[0])\n",
    "# The collected comments data set still contained some data from 2020-09-30. This is removed. \n",
    "com_data = com_data[com_data.index > \"2020-10-01\"]\n",
    "\n",
    "# Make sure all text bodies are of type string. \n",
    "com_data[\"body\"] = com_data[\"body\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 917,
   "id": "1623652e",
=======
   "execution_count": 18,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we control the used subset of the comments data, based on the time index. \n",
    "#com_data_p1 = com_data[com_data.index <= \"2020-10-07\"]\n",
    "#com_data = com_data_p1"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "6b37f501",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "__Tokenization__ <br>\n",
    "As we will also be looking into producing other textual analyses than the VADER sentiment scores, like wordclouds, we will also need to do some tokenization ourselves. \n",
    "For the body of each comment, we will do the following steps: \n",
    "   * Exclude punctuation.\n",
    "   * Exclude URLs\n",
    "   * Exclude English stop words\n",
    "   * Exclude numbers.\n",
    "   * Set everything to lower case. \n",
    "   \n",
    "The results of this preprocessing will be a new column in the comments dataframe containing the cleaned tokens of the text body. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1049,
   "id": "148c4fe3",
=======
   "execution_count": 19,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 142375/142375 [00:55<00:00, 2548.45it/s]\n"
=======
      "100%|████████████████████████████████████████████████████████████████████████| 250910/250910 [01:15<00:00, 3303.89it/s]\n"
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
     ]
    }
   ],
   "source": [
    "# Define stop words to also include punctuation\n",
    "stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "def clean_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    clean_tokens = [re.sub(r'http\\S+', '', str(i)).lower() for i in tokens if (i not in stop and str(i).isalpha())]\n",
    "    return clean_tokens\n",
    "\n",
    "com_data[\"tokens\"] = com_data.progress_apply(lambda x: clean_tokens(x[\"body\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "18a6cd85",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "__Determining whether the comments are \"Trump\" or \"Biden\" -related__ <br>\n",
    "For each of the collected comments, we need to know whether the comment relates to Trump or Biden. Our plan to achieve this is to first assign a \"politician\" variable to all comments that matches the \"politician\" value of the submission to which the comments was made. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1051,
   "id": "66d0d8c6",
=======
   "execution_count": 20,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 142375/142375 [02:40<00:00, 889.69it/s] \n"
=======
      "100%|████████████████████████████████████████████████████████████████████████| 250910/250910 [03:37<00:00, 1152.10it/s]\n"
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
     ]
    }
   ],
   "source": [
    "def determine_politician_coms(link_id):\n",
    "    #Get the id of the original submission\n",
    "    real_id = link_id[3:]   \n",
    "    # Find the politician value of the corresponding submission\n",
    "    sub_politician = sub_data.loc[sub_data['id'] == real_id]['politician']\n",
    "    sub_politician = sub_politician.values[0]\n",
    "    return sub_politician \n",
    "com_data['politician'] = com_data['link_id'].progress_apply(determine_politician_coms)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "371181dd",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "This assignment of \"politician\" values i very naive, as it does not take into account the possibility of the actual comments mentioning either of the politicians. To overcome this, we will prune the comments section tree so that whenever a comment mentions a different politician than what is currently stated as its \"politician\" value, we will remove this comment along with all comments made to that comment - the so-called children of the comment. This way, we ensure an unambiguous picture of which politician each comment relates to. \n",
    "\n",
    "This procedure requires us to also know the children of each comment, which find below:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1053,
   "id": "ada44a35",
=======
   "execution_count": 21,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 142375/142375 [55:46<00:00, 42.55it/s] \n"
=======
      "100%|████████████████████████████████████████████████████████████████████████| 250910/250910 [1:18:12<00:00, 53.47it/s]\n"
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
     ]
    }
   ],
   "source": [
    "# A list of all the id's in the comments datafram\n",
    "com_ids = list(com_data['id'].values)\n",
    "\n",
    "# We create a dictionary with keys equal to the id's in of the comments and values equal to their respective \"children\" comments\n",
    "children_dict = {com_id: [] for com_id in com_ids}\n",
    "\n",
    "for com_id in tqdm(com_ids): \n",
    "    parent_id = com_data.loc[com_data['id'] == com_id]['parent_id']\n",
    "    parent_id = parent_id.values[0]\n",
    "    parent_id = parent_id[3:]\n",
    "    if parent_id in com_ids: \n",
    "        children_dict[parent_id].append(com_id)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1054,
   "id": "617526e4",
=======
   "execution_count": 22,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 142375/142375 [00:00<00:00, 627190.13it/s]\n"
=======
      "100%|██████████████████████████████████████████████████████████████████████| 250910/250910 [00:00<00:00, 796087.03it/s]\n"
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
     ]
    }
   ],
   "source": [
    "# Append the children comments to the comments dataframe\n",
    "def determine_children(com_id):\n",
    "    return children_dict[com_id]    \n",
    "\n",
    "com_data['children_comments'] = com_data['id'].progress_apply(determine_children)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "a6e08ca7",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "Now we will figure out whether each comment itself mentions \"Trump\" or \"Biden\". "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1055,
   "id": "4be89b80",
=======
   "execution_count": 23,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 142375/142375 [42:40<00:00, 55.60it/s] \n",
      "100%|██████████| 142375/142375 [39:07<00:00, 60.65it/s] \n"
=======
      "100%|████████████████████████████████████████████████████████████████████████| 250910/250910 [1:04:39<00:00, 64.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 250910/250910 [1:03:56<00:00, 65.41it/s]\n"
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
     ]
    }
   ],
   "source": [
    "def comment_mentions_Trump(com_id):\n",
    "    mentions_Trump = False\n",
    "    tokenized_body = \" \".join(com_data.loc[com_data['id'] == com_id]['tokens'].values[0])\n",
    "    if (re.search('trump', tokenized_body)):\n",
    "        mentions_Trump = True\n",
    "        return mentions_Trump\n",
    "    \n",
    "def comment_mentions_Biden(com_id):\n",
    "    mentions_Biden = False\n",
    "    tokenized_body = \" \".join(com_data.loc[com_data['id'] == com_id]['tokens'].values[0])\n",
    "    if (re.search('biden', tokenized_body)):\n",
    "        mentions_Biden = True\n",
    "        return mentions_Biden\n",
    "    \n",
    "com_data['mentions_Trump'] = com_data['id'].progress_apply(comment_mentions_Trump)\n",
    "com_data['mentions_Biden'] = com_data['id'].progress_apply(comment_mentions_Biden)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1056,
   "id": "75cc7f7b",
=======
   "execution_count": 24,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_to_delete = []\n",
    "\n",
    "# Function to find the comments to be deleted due to amgious politician relation. \n",
    "def find_coms_to_be_deleted(com_id):\n",
    "\n",
    "    if com_id not in comments_to_delete: \n",
    "        mentions_Biden = com_data.loc[com_data['id'] == com_id]['mentions_Biden']\n",
    "        mentions_Biden = mentions_Biden.values[0]\n",
    "\n",
    "        mentions_Trump = com_data.loc[com_data['id'] == com_id]['mentions_Trump']\n",
    "        mentions_Trump = mentions_Trump.values[0]\n",
    "\n",
    "        politician = com_data.loc[com_data['id'] == com_id]['politician']\n",
    "        politician = politician.values[0]\n",
    "\n",
    "        children = com_data.loc[com_data['id'] == com_id]['children_comments']\n",
    "        children = children.values[0]\n",
    "\n",
    "        if (politician == 'Biden' and mentions_Trump) or (politician == 'Trump' and mentions_Biden): \n",
    "\n",
    "            comments_to_delete.append(com_id)\n",
    "\n",
    "            if len(children): \n",
    "                for child in children:\n",
    "                    comments_to_delete.append(child)\n",
    "                    find_coms_to_be_deleted(child)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1057,
   "id": "35ac3d02",
=======
   "execution_count": null,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 142375/142375 [2:30:55<00:00, 15.72it/s]  \n"
=======
      " 80%|█████████████████████████████████████████████████████████▉              | 201945/250910 [3:21:12<46:57, 17.38it/s]"
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
     ]
    }
   ],
   "source": [
    "for com_id in tqdm(com_ids): \n",
    "    find_coms_to_be_deleted(com_id)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1058,
   "id": "3320e752",
=======
   "execution_count": null,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_to_delete = list(set(comments_to_delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "id": "208886f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12392/12392 [14:30<00:00, 14.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for com_id in tqdm(comments_to_delete):\n",
    "    com_index = com_data.id[com_data.id == com_id].index\n",
    "    com_data = com_data.drop(com_index)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1063,
   "id": "0398be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_data.to_csv(r\"C:\\Users\\Lasse\\Desktop\\DTU\\6. semester\\Social informatik\\Exam project local\\Data\\com_data_pruned_50plusComments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c92bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pruned data\n",
    "com_data = pd.read_csv(r\"C:\\Users\\Lasse\\Desktop\\DTU\\6. semester\\Social informatik\\Exam project local\\Data\\com_data_pruned_50plusComments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a81328c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_data = com_data.groupby('author').filter(lambda x : len(x)>=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ddde8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_data.to_csv(r\"C:\\Users\\Lasse\\Desktop\\DTU\\6. semester\\Social informatik\\Exam project local\\Data\\com_data_50plusComments_pruned_30plusComments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "cbfcb61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_bodies = com_data.groupby([\"author\", \"politician\"]).apply(lambda x: \" \".join(x[\"body\"].unique()))\n",
    "\n",
    "#\" \".join(author_bodies[\"2coolfordigg2\"][\"Biden\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "a8d70364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5462"
      ]
     },
     "execution_count": 976,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(com_data[\"author\"].unique())"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_bodies = com_data.groupby([\"author\", \"politician\"]).apply(lambda x: x[\"body\"].unique())\n",
    "\n",
    "\" \".join(author_bodies[\"2coolfordigg2\"][\"Biden\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics of the comments"
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 989,
   "id": "7b8e5ada",
=======
   "execution_count": 450,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trump']"
      ]
     },
     "execution_count": 989,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(author_bodies[\"CrunchyDreads\"].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb342497",
   "metadata": {},
   "source": [
    "### Statistics of the comments"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 982,
   "id": "962fbde2",
=======
   "execution_count": 451,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the VADER sentiment analysis of the comments. \n",
    "\n",
    "#https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/\n",
    "def calculate_compound_sentiment_score(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "     \n",
    "    # The Compound score is a metric that calculates the sum of all the lexicon ratings \n",
    "    # which have been normalized between -1(most extreme negative) and +1 (most extreme positive).   \n",
    "    \n",
    "    return sentiment_dict['compound']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1037,
   "id": "4b634945",
=======
   "execution_count": 526,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5462/5462 [04:33<00:00, 19.97it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {\"Author\" : com_data[\"author\"].unique()}\n",
    "author_sentiment_df = pd.DataFrame(data)\n",
    "author_sentiment_df[\"Trump_sentiment\"] = 0\n",
    "author_sentiment_df[\"Biden_sentiment\"] = 0\n",
    "\n",
    "for author in tqdm(com_data[\"author\"].unique()):\n",
    "    related_politicians = list(author_bodies[author].index)\n",
    "    for related_politician in related_politicians:\n",
    "        if related_politician == \"Trump\": \n",
    "            author_sentiment_df.loc[author_sentiment_df[\"Author\"] == author, \"Trump_sentiment\"] = calculate_compound_sentiment_score(author_bodies[author][\"Trump\"])\n",
    "        else:\n",
    "            author_sentiment_df.loc[author_sentiment_df[\"Author\"] == author, \"Biden_sentiment\"] = calculate_compound_sentiment_score(author_bodies[author][\"Biden\"])\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1040,
   "id": "23905066",
=======
   "execution_count": 848,
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I’m guessing trump is of the belief that he paid plenty of taxes because his employees paid taxes and since he paid his employees he therefore paid those taxes'"
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_bodies[\"bk1285\"][\"Trump\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "024c4def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:05<00:00, 93.07it/s] \n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "com_data[\"compound_sentiment_score\"] = com_data[\"body\"].progress_apply(calculate_compound_sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "71b0e1c1",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "NOTE: Here, we've managed to delete even more comments leaving some authors with less than five comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
<<<<<<< HEAD
   "id": "92584d40",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "group = com_data.groupby([\"author\", \"politician\"])\n",
    "author_df_V = group.apply(lambda x: x[\"compound_sentiment_score\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
<<<<<<< HEAD
   "id": "50b40184",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author           politician\n",
       "2coolfordigg2    Biden           [0.2579, -0.1071, 0.0]\n",
       "                 Trump            [0.3595, 0.0, -0.743]\n",
       "35Lcrowww        Trump                         [0.2382]\n",
       "7ddlysuns        Trump                        [-0.1725]\n",
       "ATishbite        Trump                    [0.0, -0.926]\n",
       "                                         ...           \n",
       "verablue         Biden                            [0.0]\n",
       "                 Trump                [-0.8172, 0.2732]\n",
       "versusgorilla    Trump                         [0.3818]\n",
       "walkinman19      Trump         [0.6114, -0.25, -0.9144]\n",
       "whenimmadrinkin  Trump                         [0.4939]\n",
       "Length: 192, dtype: object"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_df_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
<<<<<<< HEAD
   "id": "c2c95ec3",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Trump'], dtype='object', name='politician')"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_comment_sentiment_dict['J_Class_Ford']['Biden'] = np.array([0])\n",
    "author_comment_sentiment_dict['J_Class_Ford']['Biden']\n",
    "author_df_V['J_Class_Ford'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
<<<<<<< HEAD
   "id": "3c956537",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to contain the authors as keys and a dict as value: {\"Biden\" : [list of sentiment scores of all Biden-related comments by author], \"Trump\" : [list of sentiment scores of all Trump-related comments by author]}\n",
    "# Each list of sentiment scores contain 0 per default corresponding to a neutral compound sentiment. \n",
    "author_comment_sentiment_dict = {author : {\"Biden\" : np.array([0]), \"Trump\": np.array([0])} for author in authors}\n",
    "for author in authors:\n",
    "    related_politicians = list(author_df_V[author].index)\n",
    "    for politician in related_politicians:\n",
    "        author_comment_sentiment_dict[author][politician] = author_df_V[author][politician]    \n",
    "        # If no comments related to the politician\n",
    "        if not list(author_comment_sentiment_dict[author][politician]):\n",
    "            author_comment_sentiment_dict[author][politician] = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "0d19136b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J_Class_Ford': {'Biden': array([0]),\n",
       "  'Trump': array([-0.296 , -0.016 , -0.7351,  0.    ,  0.4019,  0.4404,  0.5719])},\n",
       " 'cyanydeez': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.4215,  0.545 , -0.5574, -0.7992])},\n",
       " 'swDev3db': {'Biden': array([-0.6815]),\n",
       "  'Trump': array([ 0.    , -0.1513, -0.1926, -0.5106,  0.7506, -0.8074, -0.1027])},\n",
       " 'MelBabii00': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.0772, -0.5267,  0.    , -0.34  , -0.2732])},\n",
       " 'danielbot': {'Biden': array([-0.5267]), 'Trump': array([0.])},\n",
       " 'HereForAnArgument': {'Biden': array([0]),\n",
       "  'Trump': array([-0.34  , -0.3182])},\n",
       " 'LSF604': {'Biden': array([0]), 'Trump': array([0.3581, 0.    ])},\n",
       " 'Forced_Lever': {'Biden': array([0]),\n",
       "  'Trump': array([-0.0675, -0.2191, -0.7745])},\n",
       " 'californiaavocados': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.5574])},\n",
       " 'Endthenightmare2020': {'Biden': array([-0.2023,  0.3353, -0.3612]),\n",
       "  'Trump': array([0.])},\n",
       " 'Braintendo': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.3612, -0.8834,  0.6124, -0.1531,  0.6808])},\n",
       " 'CorporateCuster': {'Biden': array([0.6249]),\n",
       "  'Trump': array([-0.765 , -0.7884, -0.5994, -0.6808,  0.    ])},\n",
       " 'WittsandGrit': {'Biden': array([0.]),\n",
       "  'Trump': array([0.1027, 0.    , 0.2189])},\n",
       " 'BroadAsparagus': {'Biden': array([0.7391, 0.    , 0.4404]),\n",
       "  'Trump': array([-0.9665, -0.1779])},\n",
       " 'UnknownAverage': {'Biden': array([0.0202]),\n",
       "  'Trump': array([0.1788, 0.6124])},\n",
       " 'Wattsferatu': {'Biden': array([0.0771]), 'Trump': array([0.7867])},\n",
       " 'urabouttoberemoved': {'Biden': array([-0.1029, -0.4767]),\n",
       "  'Trump': array([-0.6597, -0.2846])},\n",
       " 'King_Mierdas': {'Biden': array([0]), 'Trump': array([0.1531])},\n",
       " 'spacemusclehampster': {'Biden': array([0.1583]),\n",
       "  'Trump': array([-0.8   ,  0.3612,  0.    , -0.8402])},\n",
       " 'urnotjustwrong': {'Biden': array([0.]), 'Trump': array([-0.6486])},\n",
       " '2coolfordigg2': {'Biden': array([ 0.2579, -0.1071,  0.    ]),\n",
       "  'Trump': array([ 0.3595,  0.    , -0.743 ])},\n",
       " 'crazytownindustries': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.2263])},\n",
       " 'Sharp_Recollections': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.3597, -0.6817, -0.743 ,  0.3612])},\n",
       " 'Meta_Digital': {'Biden': array([0.6124]),\n",
       "  'Trump': array([ 0.1027, -0.7096, -0.7976])},\n",
       " 'cheefjustice': {'Biden': array([0.1109]),\n",
       "  'Trump': array([0.4215, 0.8689, 0.5719])},\n",
       " '_WirthsLaw_': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.4019,  0.3182,  0.    ,  0.1754, -0.5362, -0.6767, -0.3182,\n",
       "          0.8356])},\n",
       " 'GaryNunchucks': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.0243, -0.3546, -0.765 ])},\n",
       " 'colourmeblue': {'Biden': array([0]), 'Trump': array([0.4939])},\n",
       " 'leavy23': {'Biden': array([0]),\n",
       "  'Trump': array([-0.5423, -0.6808, -0.128 ,  0.4215, -0.3612, -0.0258,  0.    ,\n",
       "         -0.872 , -0.4767, -0.5859,  0.5994])},\n",
       " 'ScientistSeven': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.3612,  0.6261,  0.25  ,  0.4404, -0.1779, -0.7261])},\n",
       " 'bigdaddyowl': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.7906,  0.1847, -0.4261,  0.    ])},\n",
       " 'jwak4g78qk': {'Biden': array([0]), 'Trump': array([ 0.    , -0.4588])},\n",
       " 'sillyanastssia': {'Biden': array([0]), 'Trump': array([-0.296])},\n",
       " 'Knox200': {'Biden': array([0]), 'Trump': array([0.    , 0.1326])},\n",
       " '35Lcrowww': {'Biden': array([0]), 'Trump': array([0.2382])},\n",
       " 'NemWan': {'Biden': array([0]), 'Trump': array([ 0.7351, -0.9062])},\n",
       " 'manofthemonth': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.1779,  0.4515, -0.626 ])},\n",
       " 'fourstringsofgroove': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.5267,  0.    , -0.296 , -0.4215, -0.6114])},\n",
       " 'LoudlyForBiden': {'Biden': array([0.2746]),\n",
       "  'Trump': array([0.5267, 0.4201])},\n",
       " 'prodriggs': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.2924, -0.34  , -0.5719,  0.4585, -0.024 ])},\n",
       " 'SnooEagles9792': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.4404, -0.246 ,  0.2235, -0.4749])},\n",
       " 'RottonPotatoes': {'Biden': array([0]),\n",
       "  'Trump': array([-0.3182, -0.0772, -0.6979])},\n",
       " 'StackerPentecost': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'ShopSmartShopS-Mart': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.1027])},\n",
       " 'JimmyJamesincorp': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.5574, -0.7399,  0.3612])},\n",
       " 'Philippus': {'Biden': array([0]), 'Trump': array([ 0.    , -0.5041])},\n",
       " 'idunmessedup': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.9433, -0.2559])},\n",
       " 'FertilityHollis': {'Biden': array([0]), 'Trump': array([0.7096])},\n",
       " 'Sn1p-SN4p': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.3182,  0.    , -0.5023])},\n",
       " 'danman60': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'mikerichh': {'Biden': array([0.7184, 0.7382]),\n",
       "  'Trump': array([-0.3612, -0.296 ])},\n",
       " 'oh_no_aliens': {'Biden': array([0]), 'Trump': array([-0.2263,  0.6085])},\n",
       " 'INTHEMIDSTOFLIONS': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.2023, -0.5106])},\n",
       " 'SpookyLilGal': {'Biden': array([0]), 'Trump': array([-0.3781])},\n",
       " 'evin0688': {'Biden': array([0]), 'Trump': array([-0.0772,  0.    ])},\n",
       " 'PigFarmer1': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'nyybmw122': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.5707, -0.5859,  0.296 ])},\n",
       " 'AnnatoniaMac': {'Biden': array([0]),\n",
       "  'Trump': array([-0.6214,  0.    ,  0.5719, -0.128 , -0.34  ])},\n",
       " 'BarberAnne': {'Biden': array([0]), 'Trump': array([-0.8225,  0.3182])},\n",
       " 'geekygay': {'Biden': array([0]), 'Trump': array([-0.2263])},\n",
       " 'Sloppy_Tiger': {'Biden': array([0]),\n",
       "  'Trump': array([-0.3818, -0.6354, -0.1531,  0.34  ,  0.    ])},\n",
       " 'stagfury': {'Biden': array([0]), 'Trump': array([-0.6124, -0.6705])},\n",
       " 'cutelyaware': {'Biden': array([0]), 'Trump': array([-0.34])},\n",
       " 'walkinman19': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.6114, -0.25  , -0.9144])},\n",
       " 'uglymule': {'Biden': array([0]), 'Trump': array([-0.5859])},\n",
       " 'Hockeyloogie': {'Biden': array([0]), 'Trump': array([-0.6597])},\n",
       " 'ATishbite': {'Biden': array([0]), 'Trump': array([ 0.   , -0.926])},\n",
       " 'GiggityDPT': {'Biden': array([0.7346]), 'Trump': array([-0.7184, -0.9263])},\n",
       " 'Original-Winter3057': {'Biden': array([0]), 'Trump': array([-0.8926])},\n",
       " 'verablue': {'Biden': array([0.]), 'Trump': array([-0.8172,  0.2732])},\n",
       " 'r33venasty': {'Biden': array([0]), 'Trump': array([0.8316])},\n",
       " 'jeopardy987987': {'Biden': array([-0.296 ,  0.5095]),\n",
       "  'Trump': array([ 0.4632,  0.    , -0.224 , -0.4404,  0.5801])},\n",
       " 'AmishTechno': {'Biden': array([0]), 'Trump': array([-0.5571,  0.    ])},\n",
       " 'dubman42': {'Biden': array([0]), 'Trump': array([0.    , 0.4588])},\n",
       " 'rabidstoat': {'Biden': array([0]), 'Trump': array([-0.6486,  0.128 ])},\n",
       " 'outerworldLV': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.2786, -0.7069])},\n",
       " 'ImNotNicknolte': {'Biden': array([0]), 'Trump': array([0.5972, 0.    ])},\n",
       " 'Thegreylady13': {'Biden': array([0]),\n",
       "  'Trump': array([-0.6486,  0.34  ,  0.7977])},\n",
       " 'FOXDuneRider': {'Biden': array([0]), 'Trump': array([ 0.3612, -0.2732])},\n",
       " 'notrealmate': {'Biden': array([0]), 'Trump': array([-0.3612])},\n",
       " 'jedre': {'Biden': array([0]), 'Trump': array([0.765])},\n",
       " 'BettyVonButtpants': {'Biden': array([0]), 'Trump': array([-0.4588])},\n",
       " 'rc724': {'Biden': array([0]), 'Trump': array([0.4767])},\n",
       " 'beingserial': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'GarbledMan': {'Biden': array([0]), 'Trump': array([0.4144, 0.    ])},\n",
       " 'bantargetedads': {'Biden': array([-0.4019, -0.4404]),\n",
       "  'Trump': array([-0.7351, -0.8481, -0.0475,  0.    ])},\n",
       " 'elkab0ng': {'Biden': array([0]), 'Trump': array([0.    , 0.4404])},\n",
       " 'PaperbackBuddha': {'Biden': array([0.7876, 0.0323]),\n",
       "  'Trump': array([ 0.4019, -0.25  ,  0.6486, -0.2732])},\n",
       " 'acityonthemoon': {'Biden': array([0]), 'Trump': array([0.3612, 0.    ])},\n",
       " 'celtic1888': {'Biden': array([0]), 'Trump': array([ 0.  , -0.34])},\n",
       " 'Growbigbuds': {'Biden': array([0]),\n",
       "  'Trump': array([-0.8658,  0.    ,  0.6666, -0.9153])},\n",
       " 'TTPMGP': {'Biden': array([0.8553]), 'Trump': array([0.])},\n",
       " 'overcomebyfumes': {'Biden': array([0]), 'Trump': array([0.34, 0.  ])},\n",
       " 'Giles-TheLibrarian': {'Biden': array([-0.1779]),\n",
       "  'Trump': array([ 0.2732, -0.594 , -0.7317])},\n",
       " 'ambassadorodman': {'Biden': array([-0.6027,  0.2732,  0.6652,  0.0276, -0.1027]),\n",
       "  'Trump': array([0])},\n",
       " 'FizzyBeverage': {'Biden': array([-0.25  ,  0.8529,  0.    ]),\n",
       "  'Trump': array([ 0.8074,  0.0258, -0.4939])},\n",
       " 'AZWxMan': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'htomserveaux': {'Biden': array([ 0.7018,  0.8555, -0.2939, -0.8074,  0.5423]),\n",
       "  'Trump': array([-0.5848])},\n",
       " 'TheGame81677': {'Biden': array([0.7579]),\n",
       "  'Trump': array([-0.3612,  0.    ])},\n",
       " 'Gimmeprops99': {'Biden': array([0.6808]), 'Trump': array([-0.4215])},\n",
       " 'TrumpsInvertedPenis': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.701 , -0.891 ,  0.    , -0.128 ,  0.4588])},\n",
       " 'EveningThoughts': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'CarmenFandango': {'Biden': array([0]),\n",
       "  'Trump': array([-0.835 , -0.1027, -0.5267, -0.6705,  0.0083])},\n",
       " 'that_j0e_guy': {'Biden': array([0.    , 0.9284]), 'Trump': array([0])},\n",
       " 'fbvtGjrw459iy32bo': {'Biden': array([-0.8985]), 'Trump': array([-0.6249])},\n",
       " 'clancy0001': {'Biden': array([0.6114]), 'Trump': array([0])},\n",
       " 'GrandmaesterFlash45': {'Biden': array([-0.3612]),\n",
       "  'Trump': array([-0.714 , -0.8271])},\n",
       " 'guruscotty': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.8828,  0.2263,  0.7284, -0.8943])},\n",
       " 'perplexed_43': {'Biden': array([0.7086]),\n",
       "  'Trump': array([ 0.6369, -0.6275, -0.8158])},\n",
       " 'whenimmadrinkin': {'Biden': array([0]), 'Trump': array([0.4939])},\n",
       " '_blackwholeson': {'Biden': array([0]),\n",
       "  'Trump': array([-0.6808, -0.8798,  0.0258])},\n",
       " 'cola1016': {'Biden': array([0]), 'Trump': array([0.    , 0.2716])},\n",
       " 'SASIPI': {'Biden': array([0]),\n",
       "  'Trump': array([-0.4588,  0.8021, -0.4574,  0.7689])},\n",
       " 'jayfeather31': {'Biden': array([-0.6369, -0.4133]),\n",
       "  'Trump': array([-0.9761])},\n",
       " 'Vroom_Broom': {'Biden': array([0.34]), 'Trump': array([ 0.    , -0.3612])},\n",
       " 'Betta_jazz_hands': {'Biden': array([0]), 'Trump': array([ 0.    , -0.0129])},\n",
       " 'Darkphibre': {'Biden': array([0]),\n",
       "  'Trump': array([-0.8561,  0.489 , -0.891 ])},\n",
       " 'soiledsanchez': {'Biden': array([0]), 'Trump': array([-0.25])},\n",
       " 'ruiner8850': {'Biden': array([0]), 'Trump': array([-0.4588,  0.5882])},\n",
       " 'droplivefred': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'Djmex914': {'Biden': array([-0.5574]), 'Trump': array([0])},\n",
       " 'godfetish': {'Biden': array([0.]), 'Trump': array([0])},\n",
       " 'pass-on-liberalism': {'Biden': array([ 0.8812,  0.2732, -0.34  ,  0.3612]),\n",
       "  'Trump': array([0])},\n",
       " 'neverXmiss': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.4019,  0.3898,  0.    , -0.3612, -0.3089,  0.7869, -0.3049])},\n",
       " 'sunnbeta': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.624 , -0.7717,  0.4939,  0.6553,  0.836 ])},\n",
       " 'DoneDrinkingPoison': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.4753,  0.7217, -0.8948])},\n",
       " 'Triassic_Bark': {'Biden': array([0.]), 'Trump': array([-0.6704])},\n",
       " 'JamminOnTheOne': {'Biden': array([0]), 'Trump': array([-0.7152])},\n",
       " 'Self-Aware': {'Biden': array([0]), 'Trump': array([0.0813])},\n",
       " '7ddlysuns': {'Biden': array([0]), 'Trump': array([-0.1725])},\n",
       " 'diamondunicorn08': {'Biden': array([0]),\n",
       "  'Trump': array([-0.7913, -0.9593, -0.7545,  0.7545,  0.6697])},\n",
       " 'DankaelYoung': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.3818, -0.7964, -0.3612,  0.2716])},\n",
       " 'LoserGate': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.1779,  0.1521,  0.4019,  0.6901, -0.872 ])},\n",
       " 'dej0ta': {'Biden': array([0]),\n",
       "  'Trump': array([-0.9499, -0.5047,  0.2057, -0.7194, -0.7659])},\n",
       " 'I_am_levitating': {'Biden': array([0]), 'Trump': array([ 0.5994, -0.822 ])},\n",
       " 'Atomhed': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'bballkj7': {'Biden': array([0]), 'Trump': array([-0.0552])},\n",
       " 'dedicated-pedestrian': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'HotField9281': {'Biden': array([0]), 'Trump': array([-0.5849])},\n",
       " 'appleparkfive': {'Biden': array([0]), 'Trump': array([-0.7954])},\n",
       " 'versusgorilla': {'Biden': array([0]), 'Trump': array([0.3818])},\n",
       " 'offbeat_ahmad': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'Girasol-de-Luna': {'Biden': array([0]), 'Trump': array([-0.9451, -0.9514])},\n",
       " 'RedditUserCommon': {'Biden': array([0]), 'Trump': array([-0.6901])},\n",
       " 'Reddit_FTW': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.7424,  0.0772])},\n",
       " 'CuddlePirate420': {'Biden': array([0]), 'Trump': array([-0.3875])},\n",
       " 'dumpyredditacct': {'Biden': array([0]),\n",
       "  'Trump': array([-0.7876,  0.5574, -0.8271,  0.    ])},\n",
       " 'adam_demamps_wingman': {'Biden': array([0]),\n",
       "  'Trump': array([-0.2115,  0.    ])},\n",
       " 'NanGottaBadSector': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'BellatrixLaLittleOdd': {'Biden': array([0]), 'Trump': array([0.6369])},\n",
       " 'K_J_E': {'Biden': array([0]), 'Trump': array([-0.7845])},\n",
       " 'i-was-a-ghost-once': {'Biden': array([0]), 'Trump': array([0.4378])},\n",
       " 'PrinceEmirate': {'Biden': array([0]), 'Trump': array([-0.7003])},\n",
       " 'ImInterested': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.5719, -0.34  ,  0.    ])},\n",
       " 'jedi_cat_': {'Biden': array([0.]), 'Trump': array([0])},\n",
       " 'Scaryassmanbear': {'Biden': array([ 0.    ,  0.3818, -0.2732]),\n",
       "  'Trump': array([0])},\n",
       " 'NewsgramLady': {'Biden': array([0.3417, 0.8246, 0.7845]),\n",
       "  'Trump': array([0])},\n",
       " 'FerretFarm': {'Biden': array([0.6361]), 'Trump': array([0])},\n",
       " 'kdeff': {'Biden': array([0.6249, 0.1613]), 'Trump': array([0])}}"
      ]
     },
     "execution_count": 971,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_comment_sentiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
<<<<<<< HEAD
   "id": "6744f38d",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sentiment score for Trump-related comments: 0.11310000000000002\n",
      "Mean sentiment score for Biden-related comments: 0.20096666666666665\n"
     ]
    }
   ],
   "source": [
    "# An example with author 'FizzyBeverage'\n",
    "# Print the mean sentiment score for each politician\n",
    "print(\"Mean sentiment score for Trump-related comments: \" + str(sum(author_comment_sentiment_dict['FizzyBeverage'][\"Trump\"])/len(author_comment_sentiment_dict['FizzyBeverage'][\"Trump\"])))\n",
    "print(\"Mean sentiment score for Biden-related comments: \" + str(sum(author_comment_sentiment_dict['FizzyBeverage'][\"Biden\"])/len(author_comment_sentiment_dict['FizzyBeverage'][\"Biden\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
<<<<<<< HEAD
   "id": "475c7fe7",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07802"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(author_comment_sentiment_dict['cyanydeez'][\"Trump\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
<<<<<<< HEAD
   "id": "e95a0cde",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J_Class_Ford': {'Biden': array([0]),\n",
       "  'Trump': array([-0.296 , -0.016 , -0.7351,  0.    ,  0.4019,  0.4404,  0.5719])},\n",
       " 'cyanydeez': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.4215,  0.545 , -0.5574, -0.7992])},\n",
       " 'swDev3db': {'Biden': array([-0.6815]),\n",
       "  'Trump': array([ 0.    , -0.1513, -0.1926, -0.5106,  0.7506, -0.8074, -0.1027])},\n",
       " 'MelBabii00': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.0772, -0.5267,  0.    , -0.34  , -0.2732])},\n",
       " 'danielbot': {'Biden': array([-0.5267]), 'Trump': array([0.])},\n",
       " 'HereForAnArgument': {'Biden': array([0]),\n",
       "  'Trump': array([-0.34  , -0.3182])},\n",
       " 'LSF604': {'Biden': array([0]), 'Trump': array([0.3581, 0.    ])},\n",
       " 'Forced_Lever': {'Biden': array([0]),\n",
       "  'Trump': array([-0.0675, -0.2191, -0.7745])},\n",
       " 'californiaavocados': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.5574])},\n",
       " 'Endthenightmare2020': {'Biden': array([-0.2023,  0.3353, -0.3612]),\n",
       "  'Trump': array([0.])},\n",
       " 'Braintendo': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.3612, -0.8834,  0.6124, -0.1531,  0.6808])},\n",
       " 'CorporateCuster': {'Biden': array([0.6249]),\n",
       "  'Trump': array([-0.765 , -0.7884, -0.5994, -0.6808,  0.    ])},\n",
       " 'WittsandGrit': {'Biden': array([0.]),\n",
       "  'Trump': array([0.1027, 0.    , 0.2189])},\n",
       " 'BroadAsparagus': {'Biden': array([0.7391, 0.    , 0.4404]),\n",
       "  'Trump': array([-0.9665, -0.1779])},\n",
       " 'UnknownAverage': {'Biden': array([0.0202]),\n",
       "  'Trump': array([0.1788, 0.6124])},\n",
       " 'Wattsferatu': {'Biden': array([0.0771]), 'Trump': array([0.7867])},\n",
       " 'urabouttoberemoved': {'Biden': array([-0.1029, -0.4767]),\n",
       "  'Trump': array([-0.6597, -0.2846])},\n",
       " 'King_Mierdas': {'Biden': array([0]), 'Trump': array([0.1531])},\n",
       " 'spacemusclehampster': {'Biden': array([0.1583]),\n",
       "  'Trump': array([-0.8   ,  0.3612,  0.    , -0.8402])},\n",
       " 'urnotjustwrong': {'Biden': array([0.]), 'Trump': array([-0.6486])},\n",
       " '2coolfordigg2': {'Biden': array([ 0.2579, -0.1071,  0.    ]),\n",
       "  'Trump': array([ 0.3595,  0.    , -0.743 ])},\n",
       " 'crazytownindustries': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.2263])},\n",
       " 'Sharp_Recollections': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.3597, -0.6817, -0.743 ,  0.3612])},\n",
       " 'Meta_Digital': {'Biden': array([0.6124]),\n",
       "  'Trump': array([ 0.1027, -0.7096, -0.7976])},\n",
       " 'cheefjustice': {'Biden': array([0.1109]),\n",
       "  'Trump': array([0.4215, 0.8689, 0.5719])},\n",
       " '_WirthsLaw_': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.4019,  0.3182,  0.    ,  0.1754, -0.5362, -0.6767, -0.3182,\n",
       "          0.8356])},\n",
       " 'GaryNunchucks': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.0243, -0.3546, -0.765 ])},\n",
       " 'colourmeblue': {'Biden': array([0]), 'Trump': array([0.4939])},\n",
       " 'leavy23': {'Biden': array([0]),\n",
       "  'Trump': array([-0.5423, -0.6808, -0.128 ,  0.4215, -0.3612, -0.0258,  0.    ,\n",
       "         -0.872 , -0.4767, -0.5859,  0.5994])},\n",
       " 'ScientistSeven': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.3612,  0.6261,  0.25  ,  0.4404, -0.1779, -0.7261])},\n",
       " 'bigdaddyowl': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.7906,  0.1847, -0.4261,  0.    ])},\n",
       " 'jwak4g78qk': {'Biden': array([0]), 'Trump': array([ 0.    , -0.4588])},\n",
       " 'sillyanastssia': {'Biden': array([0]), 'Trump': array([-0.296])},\n",
       " 'Knox200': {'Biden': array([0]), 'Trump': array([0.    , 0.1326])},\n",
       " '35Lcrowww': {'Biden': array([0]), 'Trump': array([0.2382])},\n",
       " 'NemWan': {'Biden': array([0]), 'Trump': array([ 0.7351, -0.9062])},\n",
       " 'manofthemonth': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.1779,  0.4515, -0.626 ])},\n",
       " 'fourstringsofgroove': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.5267,  0.    , -0.296 , -0.4215, -0.6114])},\n",
       " 'LoudlyForBiden': {'Biden': array([0.2746]),\n",
       "  'Trump': array([0.5267, 0.4201])},\n",
       " 'prodriggs': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.2924, -0.34  , -0.5719,  0.4585, -0.024 ])},\n",
       " 'SnooEagles9792': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.4404, -0.246 ,  0.2235, -0.4749])},\n",
       " 'RottonPotatoes': {'Biden': array([0]),\n",
       "  'Trump': array([-0.3182, -0.0772, -0.6979])},\n",
       " 'StackerPentecost': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'ShopSmartShopS-Mart': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.1027])},\n",
       " 'JimmyJamesincorp': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.5574, -0.7399,  0.3612])},\n",
       " 'Philippus': {'Biden': array([0]), 'Trump': array([ 0.    , -0.5041])},\n",
       " 'idunmessedup': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.9433, -0.2559])},\n",
       " 'FertilityHollis': {'Biden': array([0]), 'Trump': array([0.7096])},\n",
       " 'Sn1p-SN4p': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.3182,  0.    , -0.5023])},\n",
       " 'danman60': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'mikerichh': {'Biden': array([0.7184, 0.7382]),\n",
       "  'Trump': array([-0.3612, -0.296 ])},\n",
       " 'oh_no_aliens': {'Biden': array([0]), 'Trump': array([-0.2263,  0.6085])},\n",
       " 'INTHEMIDSTOFLIONS': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.2023, -0.5106])},\n",
       " 'SpookyLilGal': {'Biden': array([0]), 'Trump': array([-0.3781])},\n",
       " 'evin0688': {'Biden': array([0]), 'Trump': array([-0.0772,  0.    ])},\n",
       " 'PigFarmer1': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'nyybmw122': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.5707, -0.5859,  0.296 ])},\n",
       " 'AnnatoniaMac': {'Biden': array([0]),\n",
       "  'Trump': array([-0.6214,  0.    ,  0.5719, -0.128 , -0.34  ])},\n",
       " 'BarberAnne': {'Biden': array([0]), 'Trump': array([-0.8225,  0.3182])},\n",
       " 'geekygay': {'Biden': array([0]), 'Trump': array([-0.2263])},\n",
       " 'Sloppy_Tiger': {'Biden': array([0]),\n",
       "  'Trump': array([-0.3818, -0.6354, -0.1531,  0.34  ,  0.    ])},\n",
       " 'stagfury': {'Biden': array([0]), 'Trump': array([-0.6124, -0.6705])},\n",
       " 'cutelyaware': {'Biden': array([0]), 'Trump': array([-0.34])},\n",
       " 'walkinman19': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.6114, -0.25  , -0.9144])},\n",
       " 'uglymule': {'Biden': array([0]), 'Trump': array([-0.5859])},\n",
       " 'Hockeyloogie': {'Biden': array([0]), 'Trump': array([-0.6597])},\n",
       " 'ATishbite': {'Biden': array([0]), 'Trump': array([ 0.   , -0.926])},\n",
       " 'GiggityDPT': {'Biden': array([0.7346]), 'Trump': array([-0.7184, -0.9263])},\n",
       " 'Original-Winter3057': {'Biden': array([0]), 'Trump': array([-0.8926])},\n",
       " 'verablue': {'Biden': array([0.]), 'Trump': array([-0.8172,  0.2732])},\n",
       " 'r33venasty': {'Biden': array([0]), 'Trump': array([0.8316])},\n",
       " 'jeopardy987987': {'Biden': array([-0.296 ,  0.5095]),\n",
       "  'Trump': array([ 0.4632,  0.    , -0.224 , -0.4404,  0.5801])},\n",
       " 'AmishTechno': {'Biden': array([0]), 'Trump': array([-0.5571,  0.    ])},\n",
       " 'dubman42': {'Biden': array([0]), 'Trump': array([0.    , 0.4588])},\n",
       " 'rabidstoat': {'Biden': array([0]), 'Trump': array([-0.6486,  0.128 ])},\n",
       " 'outerworldLV': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.2786, -0.7069])},\n",
       " 'ImNotNicknolte': {'Biden': array([0]), 'Trump': array([0.5972, 0.    ])},\n",
       " 'Thegreylady13': {'Biden': array([0]),\n",
       "  'Trump': array([-0.6486,  0.34  ,  0.7977])},\n",
       " 'FOXDuneRider': {'Biden': array([0]), 'Trump': array([ 0.3612, -0.2732])},\n",
       " 'notrealmate': {'Biden': array([0]), 'Trump': array([-0.3612])},\n",
       " 'jedre': {'Biden': array([0]), 'Trump': array([0.765])},\n",
       " 'BettyVonButtpants': {'Biden': array([0]), 'Trump': array([-0.4588])},\n",
       " 'rc724': {'Biden': array([0]), 'Trump': array([0.4767])},\n",
       " 'beingserial': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'GarbledMan': {'Biden': array([0]), 'Trump': array([0.4144, 0.    ])},\n",
       " 'bantargetedads': {'Biden': array([-0.4019, -0.4404]),\n",
       "  'Trump': array([-0.7351, -0.8481, -0.0475,  0.    ])},\n",
       " 'elkab0ng': {'Biden': array([0]), 'Trump': array([0.    , 0.4404])},\n",
       " 'PaperbackBuddha': {'Biden': array([0.7876, 0.0323]),\n",
       "  'Trump': array([ 0.4019, -0.25  ,  0.6486, -0.2732])},\n",
       " 'acityonthemoon': {'Biden': array([0]), 'Trump': array([0.3612, 0.    ])},\n",
       " 'celtic1888': {'Biden': array([0]), 'Trump': array([ 0.  , -0.34])},\n",
       " 'Growbigbuds': {'Biden': array([0]),\n",
       "  'Trump': array([-0.8658,  0.    ,  0.6666, -0.9153])},\n",
       " 'TTPMGP': {'Biden': array([0.8553]), 'Trump': array([0.])},\n",
       " 'overcomebyfumes': {'Biden': array([0]), 'Trump': array([0.34, 0.  ])},\n",
       " 'Giles-TheLibrarian': {'Biden': array([-0.1779]),\n",
       "  'Trump': array([ 0.2732, -0.594 , -0.7317])},\n",
       " 'ambassadorodman': {'Biden': array([-0.6027,  0.2732,  0.6652,  0.0276, -0.1027]),\n",
       "  'Trump': array([0])},\n",
       " 'FizzyBeverage': {'Biden': array([-0.25  ,  0.8529,  0.    ]),\n",
       "  'Trump': array([ 0.8074,  0.0258, -0.4939])},\n",
       " 'AZWxMan': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'htomserveaux': {'Biden': array([ 0.7018,  0.8555, -0.2939, -0.8074,  0.5423]),\n",
       "  'Trump': array([-0.5848])},\n",
       " 'TheGame81677': {'Biden': array([0.7579]),\n",
       "  'Trump': array([-0.3612,  0.    ])},\n",
       " 'Gimmeprops99': {'Biden': array([0.6808]), 'Trump': array([-0.4215])},\n",
       " 'TrumpsInvertedPenis': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.701 , -0.891 ,  0.    , -0.128 ,  0.4588])},\n",
       " 'EveningThoughts': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'CarmenFandango': {'Biden': array([0]),\n",
       "  'Trump': array([-0.835 , -0.1027, -0.5267, -0.6705,  0.0083])},\n",
       " 'that_j0e_guy': {'Biden': array([0.    , 0.9284]), 'Trump': array([0])},\n",
       " 'fbvtGjrw459iy32bo': {'Biden': array([-0.8985]), 'Trump': array([-0.6249])},\n",
       " 'clancy0001': {'Biden': array([0.6114]), 'Trump': array([0])},\n",
       " 'GrandmaesterFlash45': {'Biden': array([-0.3612]),\n",
       "  'Trump': array([-0.714 , -0.8271])},\n",
       " 'guruscotty': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.8828,  0.2263,  0.7284, -0.8943])},\n",
       " 'perplexed_43': {'Biden': array([0.7086]),\n",
       "  'Trump': array([ 0.6369, -0.6275, -0.8158])},\n",
       " 'whenimmadrinkin': {'Biden': array([0]), 'Trump': array([0.4939])},\n",
       " '_blackwholeson': {'Biden': array([0]),\n",
       "  'Trump': array([-0.6808, -0.8798,  0.0258])},\n",
       " 'cola1016': {'Biden': array([0]), 'Trump': array([0.    , 0.2716])},\n",
       " 'SASIPI': {'Biden': array([0]),\n",
       "  'Trump': array([-0.4588,  0.8021, -0.4574,  0.7689])},\n",
       " 'jayfeather31': {'Biden': array([-0.6369, -0.4133]),\n",
       "  'Trump': array([-0.9761])},\n",
       " 'Vroom_Broom': {'Biden': array([0.34]), 'Trump': array([ 0.    , -0.3612])},\n",
       " 'Betta_jazz_hands': {'Biden': array([0]), 'Trump': array([ 0.    , -0.0129])},\n",
       " 'Darkphibre': {'Biden': array([0]),\n",
       "  'Trump': array([-0.8561,  0.489 , -0.891 ])},\n",
       " 'soiledsanchez': {'Biden': array([0]), 'Trump': array([-0.25])},\n",
       " 'ruiner8850': {'Biden': array([0]), 'Trump': array([-0.4588,  0.5882])},\n",
       " 'droplivefred': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'Djmex914': {'Biden': array([-0.5574]), 'Trump': array([0])},\n",
       " 'godfetish': {'Biden': array([0.]), 'Trump': array([0])},\n",
       " 'pass-on-liberalism': {'Biden': array([ 0.8812,  0.2732, -0.34  ,  0.3612]),\n",
       "  'Trump': array([0])},\n",
       " 'neverXmiss': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.4019,  0.3898,  0.    , -0.3612, -0.3089,  0.7869, -0.3049])},\n",
       " 'sunnbeta': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    ,  0.624 , -0.7717,  0.4939,  0.6553,  0.836 ])},\n",
       " 'DoneDrinkingPoison': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.4753,  0.7217, -0.8948])},\n",
       " 'Triassic_Bark': {'Biden': array([0.]), 'Trump': array([-0.6704])},\n",
       " 'JamminOnTheOne': {'Biden': array([0]), 'Trump': array([-0.7152])},\n",
       " 'Self-Aware': {'Biden': array([0]), 'Trump': array([0.0813])},\n",
       " '7ddlysuns': {'Biden': array([0]), 'Trump': array([-0.1725])},\n",
       " 'diamondunicorn08': {'Biden': array([0]),\n",
       "  'Trump': array([-0.7913, -0.9593, -0.7545,  0.7545,  0.6697])},\n",
       " 'DankaelYoung': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.3818, -0.7964, -0.3612,  0.2716])},\n",
       " 'LoserGate': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.1779,  0.1521,  0.4019,  0.6901, -0.872 ])},\n",
       " 'dej0ta': {'Biden': array([0]),\n",
       "  'Trump': array([-0.9499, -0.5047,  0.2057, -0.7194, -0.7659])},\n",
       " 'I_am_levitating': {'Biden': array([0]), 'Trump': array([ 0.5994, -0.822 ])},\n",
       " 'Atomhed': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'bballkj7': {'Biden': array([0]), 'Trump': array([-0.0552])},\n",
       " 'dedicated-pedestrian': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'HotField9281': {'Biden': array([0]), 'Trump': array([-0.5849])},\n",
       " 'appleparkfive': {'Biden': array([0]), 'Trump': array([-0.7954])},\n",
       " 'versusgorilla': {'Biden': array([0]), 'Trump': array([0.3818])},\n",
       " 'offbeat_ahmad': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'Girasol-de-Luna': {'Biden': array([0]), 'Trump': array([-0.9451, -0.9514])},\n",
       " 'RedditUserCommon': {'Biden': array([0]), 'Trump': array([-0.6901])},\n",
       " 'Reddit_FTW': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.    , -0.7424,  0.0772])},\n",
       " 'CuddlePirate420': {'Biden': array([0]), 'Trump': array([-0.3875])},\n",
       " 'dumpyredditacct': {'Biden': array([0]),\n",
       "  'Trump': array([-0.7876,  0.5574, -0.8271,  0.    ])},\n",
       " 'adam_demamps_wingman': {'Biden': array([0]),\n",
       "  'Trump': array([-0.2115,  0.    ])},\n",
       " 'NanGottaBadSector': {'Biden': array([0]), 'Trump': array([0.])},\n",
       " 'BellatrixLaLittleOdd': {'Biden': array([0]), 'Trump': array([0.6369])},\n",
       " 'K_J_E': {'Biden': array([0]), 'Trump': array([-0.7845])},\n",
       " 'i-was-a-ghost-once': {'Biden': array([0]), 'Trump': array([0.4378])},\n",
       " 'PrinceEmirate': {'Biden': array([0]), 'Trump': array([-0.7003])},\n",
       " 'ImInterested': {'Biden': array([0]),\n",
       "  'Trump': array([ 0.5719, -0.34  ,  0.    ])},\n",
       " 'jedi_cat_': {'Biden': array([0.]), 'Trump': array([0])},\n",
       " 'Scaryassmanbear': {'Biden': array([ 0.    ,  0.3818, -0.2732]),\n",
       "  'Trump': array([0])},\n",
       " 'NewsgramLady': {'Biden': array([0.3417, 0.8246, 0.7845]),\n",
       "  'Trump': array([0])},\n",
       " 'FerretFarm': {'Biden': array([0.6361]), 'Trump': array([0])},\n",
       " 'kdeff': {'Biden': array([0.6249, 0.1613]), 'Trump': array([0])}}"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_comment_sentiment_dict"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "b1ea8544",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "# 3 Tools, theory and analysis"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "c4b99ca5",
=======
>>>>>>> cbbef52186267bed007ff7f92025f8bc69d6f11e
   "metadata": {},
   "source": [
    "# 4 Discussion\n",
    "\n",
    "### What is still missing?\n",
    "\n",
    "### What could be improved?\n",
    "\n",
    "It would undoubtedly have been interesting to investigate the political content on r/politics over a longer time period, e.g. six months preceeding the election day, which would allow for the detection of longer term trends in redditor activity and sentiment. For such a scope to be feasible, bigger computational muscles than what the group members had at their disposal. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
